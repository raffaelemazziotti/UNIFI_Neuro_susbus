<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.33">

  <meta name="author" content="Raffaele M Mazziotti, PhD">
  <title>Neuroscience of social-cognitive enhancement for well-being and Neural bases of decision processes</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link rel="stylesheet" href="slide_style.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="images/logo/NEUROFARBA.svg" data-background-position="center 10%" data-background-size="500px" data-state="title-slide" class="quarto-title-block center">
  <h1 class="title">Neuroscience of social-cognitive enhancement for well-being and Neural bases of decision processes</h1>
  <p class="subtitle">Module 1 - Sensory Systems</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Raffaele M Mazziotti, PhD 
</div>
        <p class="quarto-title-affiliation">
            University of Florence
          </p>
    </div>
</div>

</section>
<section id="beyond-the-five-senses" class="slide level2 center">
<h2>Beyond the “Five Senses”</h2>
<p>The idea that humans have only <code>five senses</code> is a historical simplification.</p>
<div class="info-box">
<p>What we call a <code>sense</code> is any system that:</p>
<ul>
<li><code>detects</code> a specific form of energy or chemical signal</li>
<li><code>converts</code> it into neural activity</li>
<li><code>provides</code> information about the body or the environment</li>
</ul>
</div>
<p>By this definition, the nervous system supports many <code>parallel</code> sensory channels, often operating outside awareness.</p>
<div class="tip">
<p><strong>The brain does not experience “the world” directly.</strong><br>
It constructs reality from multiple specialized <code>input streams</code>, some obvious, some silent.</p>
</div>
</section>
<section id="additional-sensory-systems" class="slide level2 center">
<h2>Additional Sensory Systems</h2>
<p>Beyond <code>vision</code>, <code>audition</code>, <code>smell</code>, <code>taste</code>, and <code>touch</code>, the nervous system includes:</p>
<div class="colummns">
<div class="column">
<div class="info-box">
<p><span class="highlight">Equilibrioception (vestibular sense)</span><br>
Signals head position and movement, supporting <code>balance</code>, posture, and stable vision.</p>
<p><span class="highlight">Proprioception</span><br>
Provides continuous information about <code>limb position</code>, muscle stretch, and joint angle, even with eyes closed.</p>
<p><span class="highlight">Interoception</span><br>
Monitors the <code>internal state</code> of the body, including heart rate, respiration, hunger, visceral pain, and arousal.</p>
</div>
</div><div class="column">
<div class="info-box">
<p><span class="highlight">Nociception</span><br>
Detection of <code>harmful stimuli</code>. It is <code>not</code> pain, which is a perceptual and emotional construct.</p>
<p><span class="highlight">Thermoception</span><br>
Sensing <code>temperature</code> changes.</p>
<p><span class="highlight">Pruriception (Itch)</span><br>
A distinct sensory modality, not just weak pain.</p>
<p><span class="highlight">Chemoception (internal)</span><br>
Detection of <code>blood chemistry</code> such as CO₂.</p>
</div>
</div></div>
</section>
<section id="what-is-a-sensory-system" class="slide level2 center">
<h2>What is a sensory system</h2>
<div class="columns">
<div class="column">
<p>A sensory system allows the nervous system to <code>detect</code> and process <code>stimuli</code> from the environment.</p>
<blockquote>
<p>Each system is specialized for a particular form of energy or stimulus.</p>
</blockquote>
<p>Despite their differences, sensory systems share common organizational principles.</p>
<div class="info-box">
<p><span class="highlight">Sensory Transduction</span></p>
<p>Sensory systems work by converting <code>physical stimuli</code> into <code>neural signals</code>. This process is called <strong><code>transduction</code></strong>.</p>
</div>
</div><div class="column">
<blockquote>
<p><span class="highlight">Sensory receptors</span>: Sensory transduction begins at <strong><span class="highlight">sensory receptors</span></strong>.</p>
</blockquote>
<div class="info-box">
<p>Different receptors are tuned to different stimulus types:</p>
<ul>
<li><code>Photoreceptors</code> detect light<br>
</li>
<li><code>Mechanoreceptors</code> detect touch and vibration<br>
</li>
<li><code>Chemoreceptors</code> detect chemicals<br>
</li>
<li><code>Nociceptors</code> detect damaging stimuli<br>
</li>
</ul>
</div>
</div></div>
</section>
<section id="sensory-neural-code" class="slide level2 center">
<h2>Sensory Neural Code</h2>
<div class="columns">
<div class="column">
<p>Sensory transduction begins at <span class="highlight">sensory receptors</span>.</p>
<div class="info-box">
<p><span class="highlight">Receptor potentials</span></p>
<p>Sensory receptors generate receptor potentials, graded changes in membrane potential. Stronger stimuli generally produce larger receptor potentials. If threshold is reached, action potentials are generated.</p>
</div>
<div class="card">
<p>Stimulus intensity is <code>encoded</code> in two main ways:</p>
<ul>
<li>Firing rate of action potentials<br>
</li>
<li>Number of activated receptors</li>
</ul>
</div>
</div><div class="column">
<div class="info-box">
<p>Receptive fields</p>
<p>A <strong>receptive field</strong> is the region of sensory space that influences a neuron.</p>
<p>Examples include:</p>
<ul>
<li>A patch of skin<br>
</li>
<li>A region of the retina<br>
</li>
<li>A specific sound frequency</li>
</ul>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sens_RF_touch.jpg" class="quarto-figure quarto-figure-center" width="300"></p>
</figure>
</div>
</div></div>
</section>
<section id="sensory-pathways" class="slide level2 center">
<h2>Sensory pathways</h2>
<div class="columns">
<div class="column">
<p>Most sensory systems follow a common pathway:</p>
<ol type="1">
<li>Peripheral receptor<br>
</li>
<li>Entry into CNS<br>
</li>
<li>Relay through the thalamus<br>
</li>
<li>Projection to primary sensory cortex</li>
</ol>
<div class="info-box">
<p>The <span class="highlight">thalamus</span> plays a central role in sensory processing. It does more than <code>relay</code> information. It actively <code>modulates</code> and organizes sensory signals before they reach cortex.</p>
</div>
</div><div class="column">
<blockquote>
<p>There is one <strong>exception</strong> the <code>olfaction</code>: The olfactory system does not relay through the thalamus, but the signal reaches cortex directly.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_sensory_pathways.jpg" class="quarto-figure quarto-figure-center" width="300"></p>
</figure>
</div>
</div></div>
</section>
<section id="primary-sensory-cortex" class="slide level2 center">
<h2>Primary sensory cortex</h2>
<div class="columns">
<div class="column">
<p>Each sensory system has a <strong>primary cortical area</strong>.</p>
<div class="info-box">
<p>These areas:</p>
<ul>
<li>Serve as the <code>entry point</code> for cortical processing<br>
</li>
<li>Receive <code>organized</code> sensory input<br>
</li>
<li>Preserve <code>spatial relationships</code><br>
</li>
</ul>
</div>
<blockquote>
<p>Damage here produces <code>modality-specific</code> deficits.</p>
</blockquote>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_sensory_pathways.png" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="distributed-processing" class="slide level2 center">
<h2>Distributed processing</h2>
<div class="columns">
<div class="column">
<p>Perception does not arise in a single area.</p>
<div class="info-box">
<p>Sensory information is processed across:</p>
<ol type="1">
<li>Primary cortex<br>
</li>
<li>Secondary areas<br>
</li>
<li>Association cortices<br>
</li>
</ol>
</div>
<blockquote>
<p>Perception is an <code>emergent property</code> of distributed networks.</p>
</blockquote>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_association.png" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="vision" class="slide level2 center">
<h2>Vision</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>The visual system responds to <span class="highlight">electromagnetic radiation</span> in the visible spectrum.</p>
<p>Key <code>properties</code> of light include:</p>
<ul>
<li><code>Wavelength</code><br>
</li>
<li><code>Intensity</code></li>
</ul>
<p>These properties are transformed into neural signals by the <code>retina</code>.</p>
</div>
<div class="info-box">
<p>A ‘sensory window’ is the part of a physical dimension that a biological system can detect. What lies outside the window is not perceived, but it still exists. <strong>Human vision</strong> : Sensitive roughly to wavelengths between <code>~400 nm (violet)</code> and <code>~700 nm (red)</code></p>
</div>
</div><div class="column">
<p><img data-src="images/sen_spectrum.jpg" class="quarto-figure quarto-figure-right" width="500"> <img data-src="images/sen_sensory_win.jpg" class="quarto-figure quarto-figure-center" width="400"></p>
</div></div>
</section>
<section id="anatomy-of-the-eye" class="slide level2 center">
<h2>Anatomy of the eye</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Light enters the eye through several <code>structures</code>:</p>
<ul>
<li><span class="highlight">Cornea</span><br>
</li>
<li><span class="highlight">Pupil</span><br>
</li>
<li><span class="highlight">Lens</span></li>
<li><span class="highlight">Retina</span><br>
</li>
</ul>
</div>
<div class="card">
<p>The <span class="highlight">Retina</span> is organized in <code>layers</code>. Light passes through several cell layers before reaching photoreceptors. Neural processing begins within the retina itself.</p>
</div>
</div><div class="column">
<p><img data-src="images/sen_eye.png" class="quarto-figure quarto-figure-center" width="400"> <img data-src="images/sen_retina.png" class="quarto-figure quarto-figure-center" width="400"></p>
</div></div>
</section>
<section id="photoreceptors" class="slide level2 center">
<h2>Photoreceptors</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Photoreceptors are specialized cells that respond to light.</p>
</blockquote>
<div class="info-box">
<p>There are two main types:</p>
<ul>
<li><span class="highlight">Rods</span><br>
</li>
<li><span class="highlight">Cones</span><br>
</li>
</ul>
</div>
<div class="card">
<p><code>Rods</code> are highly sensitive to light. They are specialized for:</p>
<ul>
<li><code>Low-light</code> conditions (Night vision - Scotopic)</li>
<li><code>No color</code> information</li>
</ul>
</div>
</div><div class="column">
<div class="card">
<p><code>Cones</code> are less sensitive to light. They are specialized for:</p>
<ul>
<li>Daylight vision<br>
</li>
<li>Color perception<br>
</li>
<li>High spatial resolution</li>
</ul>
<p>Humans typically have <code>3 cone types</code>.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_photoreceptors.png" class="quarto-figure quarto-figure-center" width="400"></p>
</figure>
</div>
</div></div>
</section>
<section id="the-fovea-and-the-optic-nerve" class="slide level2 center">
<h2>The fovea and the Optic Nerve</h2>
<div class="columns">
<div class="column">
<div class="card">
<p>The <span class="highlight">fovea</span> is a small region near the center of the retina. It contains a <code>high density of cones</code>. It provides the <code>highest visual acuity</code>.</p>
</div>
<div class="info-box">
<p>In addition to photoreceptors, the retina contains:</p>
<ul>
<li><code>Bipolar</code> cells</li>
<li><code>Horizontal</code> cells<br>
</li>
<li><code>Amacrine</code> cells<br>
</li>
<li><code>Ganglion</code> cells</li>
</ul>
<p>These cells shape and refine visual signals.</p>
</div>
</div><div class="column">
<div class="card">
<p>The axons of ganglion cells form the <span class="highlight">optic nerve</span>.</p>
<p>This nerve carries visual information to the brain.</p>
<p>Where the optic nerve exits the retina, there are no photoreceptors. This creates the <code>blind spot</code>.</p>
</div>
<p><img data-src="images/sen_fovea.jpg" class="quarto-figure quarto-figure-left" width="250"> <img data-src="images/sen_rgc.jpg" class="quarto-figure quarto-figure-right" width="250"></p>
</div></div>
</section>
<section id="retinal-ganglion-cells-rgc" class="slide level2 center">
<h2>Retinal ganglion cells (RGC)</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Retinal ganglion cells are the <code>output</code> neurons of the retina. They receive input indirectly from photoreceptors through bipolar and amacrine cells. Their axons form the <code>optic nerve</code>.</p>
</blockquote>
<div class="info-box">
<p>Retinal ganglion cell <code>receptive fields</code> are <span class="highlight">circular</span> and organized into [2 regions]:</p>
<ul>
<li>A <code>central</code> region<br>
</li>
<li>A <code>surrounding</code> region</li>
</ul>
<p>Light affects these regions in <code>opposite</code> ways.</p>
</div>
</div><div class="column">
<p><img data-src="images/sen_rgc_rf.png" class="quarto-figure quarto-figure-center" width="350"> <img data-src="images/sen_rgc_rf1.png" class="quarto-figure quarto-figure-center" width="380"></p>
</div></div>
</section>
<section id="rgc-receptive-field" class="slide level2 center">
<h2>RGC Receptive Field</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>In <span class="highlight">ON-center</span> ganglion cells:</p>
<ul>
<li>Light in the center increases firing<br>
</li>
<li>Light in the surround decreases firing</li>
</ul>
<blockquote>
<p>They respond best to a bright spot on a darker background.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_rgc_rf_on.jpg" class="quarto-figure quarto-figure-center" width="150"></p>
</figure>
</div>
</div>
</div><div class="column">
<div class="info-box">
<p>In <span class="highlight">OFF-center</span> ganglion cells:</p>
<ul>
<li>Light in the center decreases firing<br>
</li>
<li>Light in the surround increases firing</li>
</ul>
<blockquote>
<p>They respond best to a dark spot on a brighter background.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_rgc_rf_off.jpg" class="quarto-figure quarto-figure-center" width="150"></p>
</figure>
</div>
</div>
</div></div>
</section>
<section id="rgc-receptive-field-1" class="slide level2 center">
<h2>RGC Receptive Field</h2>
<div class="card">
<p>Uniform illumination produces weak responses. his makes the RGC sensitive to <code>changes</code> in relative illumination across space-time.</p>
</div>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Center–surround organization emphasizes:</p>
<ul>
<li><code>Contrast</code></li>
<li><code>Changes</code> in light intensity<br>
</li>
<li>No relation with the absolute light levels</li>
</ul>
</div>
</div><div class="column">
<div class="info-box">
<p>Center-surround receptive fields arise from <code>retinal circuitry</code>.</p>
<p>Key contributors include:</p>
<ul>
<li>Bipolar cells<br>
</li>
<li>Horizontal cells<br>
</li>
<li>Amacrine cells</li>
</ul>
<p><code>Lateral interactions</code> are essential.</p>
</div>
</div></div>
</section>
<section id="visual-acuity" class="slide level2 center">
<h2>Visual acuity</h2>
<div class="columns">
<div class="column">
<blockquote>
<p><span class="highlight">Visual acuity</span> refers to the ability to resolve fine spatial detail.</p>
</blockquote>
<div class="info-box">
<p>Visual acuity is constrained by multiple factors:</p>
<ul>
<li>Density of photoreceptors in the retina<br>
</li>
<li>Size of receptive fields<br>
</li>
<li>Cortical magnification in visual cortex</li>
</ul>
<p>Acuity is highest in the <code>fovea</code> and decreases toward the periphery.</p>
</div>
</div><div class="column">
<blockquote>
<p><code>Eye movements</code> continuously place objects of interest onto high-acuity regions (Fovea).</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_vis_acuity.jpg" class="quarto-figure quarto-figure-center" width="450"></p>
</figure>
</div>
</div></div>
</section>
<section id="from-retina-to-the-brain" class="slide level2 center">
<h2>From retina to the Brain</h2>
<div class="columns">
<div class="column">
<div class="card">
<p>After retinal processing, visual information leaves the eye through the <strong>optic nerve</strong>. Each optic nerve carries information from <code>one eye</code>. At this stage, information is <code>segregated</code> by eye. The optic nerves meet at the <span class="highlight">optic chiasm</span>. Here, some axons cross to the opposite side of the brain. This crossing is <code>partial</code>, not complete.</p>
</div>
<div class="info-box">
<p>The <code>Crossing Rule</code>:</p>
<ul>
<li><p>Axons from the <span class="highlight">nasal</span> retina <strong>cross</strong> at the chiasm.</p></li>
<li><p>Axons from the <span class="highlight">temporal</span> retina remain on the <strong>same side</strong>.</p></li>
</ul>
<p>Each hemisphere receives information from the <span class="highlight">contralateral</span> visual field.</p>
</div>
</div><div class="column">
<div class="info-box">
<p><strong>Ipsilateral</strong><br>
Located on the <em>same side</em> of the body as the structure or reference point.</p>
<p><strong>Contralateral</strong><br>
Located on the <em>opposite side</em> of the body relative to the structure or reference point.</p>
</div>
<div class="info-box">
<p>After the chiasm:</p>
<ul>
<li>Left hemisphere processes right visual field<br>
</li>
<li>Right hemisphere processes left visual field</li>
</ul>
</div>
</div></div>
</section>
<section id="the-thalamus" class="slide level2 center">
<h2>The thalamus</h2>
<div class="columns">
<div class="column">
<div class="card">
<p>Beyond the chiasm, axons continue as the <code>optic tract</code>. Most optic tract fibers synapse in the <code>thalamus</code>. This relay is obligatory for <code>conscious vision</code>.</p>
</div>
<div class="info-box">
<p>Visual information synapses in the <span class="highlight">lateral geniculate nucleus</span> (LGN).</p>
<p>The LGN:</p>
<ul>
<li><code>Preserves</code> retinal organization<br>
</li>
<li>Maintains <code>separation</code> of inputs (monocular)<br>
</li>
<li><code>Modulates</code> signal flow to cortex<br>
</li>
<li>Receptive fields are similar to those of RGC (circular)</li>
</ul>
</div>
</div><div class="column">
<p><img data-src="images/sen_vis_field.jpg" class="quarto-figure quarto-figure-center" width="300"> <img data-src="images/sen_talamus.jpg" class="quarto-figure quarto-figure-center" width="250"></p>
</div></div>
</section>
<section id="input-to-v1" class="slide level2 center">
<h2>Input to V1</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Axons from the lateral geniculate nucleus project to V1 (Primary Visual Cortex). These projections travel via the <code>optic radiations</code>. Arriving to the <code>IV layer</code> of V1. Each hemisphere represents the <strong>contralateral visual field</strong>.</p>
</blockquote>
<div class="info-box">
<p>V1 is organized <span class="highlight">retinotopically</span>.</p>
<p>This means that:</p>
<ul>
<li>Neighboring points in the retina<br>
</li>
<li>Map to neighboring points in cortex</li>
</ul>
<p><code>Spatial relationships</code> are preserved.</p>
</div>
</div><div class="column">
<div class="info-box">
<p><span class="highlight">Cortical Magnification Factor</span>:Retinotopy is not uniform.</p>
<p>The fovea occupies a disproportionately large area of V1.</p>
<p>This reflects:</p>
<ul>
<li>High cone density<br>
</li>
<li>High visual acuity</li>
</ul>
<p>Central vision is overrepresented.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_retinotopy.jpg" class="quarto-figure quarto-figure-center" width="400"></p>
</figure>
</div>
</div></div>
</section>
<section id="what-v1-neurons-encode" class="slide level2 center">
<h2>What V1 neurons encode</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Neurons in V1 respond to <code>simple visual features</code> and start integrating the <code>binocular</code> input.</p>
</blockquote>
<div class="info-box">
<p>Features encoded:</p>
<ul>
<li><code>Edges</code><br>
</li>
<li><code>Orientation</code><br>
</li>
<li><code>Spatial location</code></li>
<li><code>Binocularity</code> from layer 2/3</li>
</ul>
<p>V1 extracts structure from retinal input.</p>
</div>
</div><div class="column">
<p><img data-src="images/sen_vispath_v1.jpg" class="quarto-figure quarto-figure-center" width="400"> <img data-src="images/sen_od_columns.jpg" class="quarto-figure quarto-figure-center" width="300"></p>
</div></div>
</section>
<section id="v1-receptive-fields" class="slide level2 center">
<h2>V1 Receptive Fields</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Neurons in primary visual cortex have receptive fields that differ from those in the retina. <strong>They are not circular!</strong> They are <code>elongated</code> and selective for specific visual features.</p>
</blockquote>
<div class="info-box">
<p>Each V1 neuron prefers a specific orientation. Rotation of the stimulus away from the preferred orientation reduces the response.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_v1_rf_shape.jpg" class="quarto-figure quarto-figure-center" width="300"></p>
</figure>
</div>
</div><div class="column">
<div class="info-box">
<p><span class="highlight">Even-symmetric</span> receptive fields have:</p>
<ul>
<li>Symmetric ON and OFF regions<br>
</li>
<li>Strong responses to bars</li>
</ul>
<p>They respond best to a bright or dark <code>line</code> at the preferred orientation.</p>
</div>
<div class="info-box">
<p><span class="highlight">Odd-symmetric</span> receptive fields have:</p>
<ul>
<li>Asymmetric ON and OFF regions<br>
</li>
<li>Strong responses to edges</li>
</ul>
<p>They are particularly sensitive to <code>luminance transitions</code>.</p>
</div>
</div></div>
</section>
<section id="v1-receptive-fields-2" class="slide level2 center">
<h2>V1 Receptive Fields 2</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p><span class="highlight">Simple cells</span> have:</p>
<ul>
<li>Clearly defined ON and OFF subregions<br>
</li>
<li>Strong orientation selectivity<br>
</li>
<li>Sensitivity to exact stimulus position and polarity</li>
</ul>
</div>
<div class="info-box">
<p><span class="highlight">Complex cells</span> also show <code>orientation</code> selectivity.</p>
<ul>
<li>Lack clearly separated ON and OFF regions<br>
</li>
<li>Are less sensitive to exact position</li>
</ul>
<p>They <code>integrate</code> input over space.</p>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_rf_simple_complex.png" class="quarto-figure quarto-figure-center" width="450"></p>
</figure>
</div>
</div></div>
</section>
<section id="a-feedforward-model-of-vision" class="slide level2 center">
<h2>A feedforward model of vision</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>In the <code>feedforward models</code>:</p>
<ul>
<li>Simple features are combined into complex ones</li>
<li>Features become more abstract<br>
</li>
<li>Sensitivity to exact position decreases</li>
</ul>
</div>
<div class="info-box">
<p>Feedforward models are <span class="highlight">incomplete</span>.</p>
<p>They do not fully explain:</p>
<ul>
<li><code>Contextual</code> effects<br>
</li>
<li><code>Attention</code><br>
</li>
<li><a href="https://www.illusionsindex.org/i">Visual illusions</a></li>
</ul>
<p>Additional interactions are required.</p>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><video data-src="images/sen_rf_video.mp4" class="quarto-figure quarto-figure-center" width="450" controls=""><a href="images/sen_rf_video.mp4">Video</a></video></p>
</figure>
</div>
</div></div>
</section>
<section id="higher-order-visual-cortex" class="slide level2 center">
<h2>Higher-order visual cortex</h2>
<div class="card">
<p>Beyond V1, visual information diverges. Multiple cortical areas specialize in different aspects of vision. These areas form distributed processing streams.</p>
</div>
<div class="info-box">
<p>Visual processing splits into two dominant pathways:</p>
<ul>
<li><code>Ventral</code> stream<br>
</li>
<li><code>Dorsal</code> stream</li>
</ul>
<p>They differ in anatomy, function, and behavioral relevance.</p>
</div>
</section>
<section id="the-what-and-where-pathways" class="slide level2 center">
<h2>The “what” and “where” pathways</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>The <span class="highlight">ventral stream</span> runs from occipital to temporal cortex.</p>
<p>It is primarily involved in:</p>
<ul>
<li><code>Object</code> recognition<br>
</li>
<li><code>Shape</code> and <code>color</code> processing<br>
</li>
<li><code>Face</code> perception</li>
</ul>
<blockquote>
<p>It answers the question: <code>What is it?</code></p>
</blockquote>
</div>
</div><div class="column">
<div class="info-box">
<p>The <span class="highlight">dorsal stream</span> runs from occipital to parietal cortex.</p>
<p>It is involved in:</p>
<ul>
<li><code>Spatial</code> localization<br>
</li>
<li><code>Motion</code> processing<br>
</li>
<li>Visually guided <code>actions</code></li>
</ul>
<blockquote>
<p>It answers the question: <code>Where is it?</code></p>
</blockquote>
</div>
</div></div>
</section>
<section id="beyond-what-and-where" class="slide level2 center">
<h2>Beyond what and where</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>The two-stream model is a simplification.</p>
<p>Modern views emphasize:</p>
<ul>
<li><code>Interaction</code> between streams<br>
</li>
<li><code>Feedback</code> connections<br>
</li>
<li>Task-dependent processing</li>
</ul>
<p>Vision is dynamic, not strictly hierarchical.</p>
</div>
<div class="info-box">
<p>Higher-order areas send feedback to earlier visual cortex (<code>top-down</code> stream).</p>
<ul>
<li>Attention<br>
</li>
<li>Contextual effects</li>
<li>Prediction</li>
</ul>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_what_where.jpg" class="quarto-figure quarto-figure-center" width="400"></p>
</figure>
</div>
</div></div>
</section>
<section id="the-ventral-stream-and-identity" class="slide level2 center">
<h2>The ventral stream and identity</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Faces detection and recognition is a <span class="highlight">Holistic process</span>. This means that faces are processed as integrated wholes.</p>
</blockquote>
<div class="info-box">
<p>A key region for face perception is the <span class="highlight">fusiform area</span> of the temporal lobe.</p>
<p>It is involved in:</p>
<ul>
<li><code>Recognizing</code> individual faces<br>
</li>
<li><code>Discriminating</code> subtle facial features</li>
</ul>
</div>
</div><div class="column">
<p><img data-src="images/sen_faces_inversion.gif" class="quarto-figure quarto-figure-center" width="400"> <video data-src="images/sen_faces_illusion.mp4" class="quarto-figure quarto-figure-center" width="400" controls=""><a href="images/sen_faces_illusion.mp4">Video</a></video></p>
</div></div>
</section>
<section id="damage-to-the-what-pathway" class="slide level2 center">
<h2>Damage to the what pathway</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Damage to ventral visual cortex can spare basic vision. Patients may see objects clearly but fail to identify or discriminate objects.</p>
</blockquote>
<div class="info-box">
<p><span class="highlight">Prosopagnosia</span> is a selective impairment in face recognition.</p>
<p>Affected individuals:</p>
<ul>
<li>Can (or cannot, in severe cases) see faces<br>
</li>
<li>Cannot <code>recognize</code> faces</li>
</ul>
<p>Other visual abilities are often preserved.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Individuals with prosopagnosia often rely on:</p>
<ul>
<li>Voice<br>
</li>
<li>Clothing<br>
</li>
<li>Contextual cues<br>
</li>
</ul>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_oliver_sacks.jpg" class="quarto-figure quarto-figure-center" width="200"></p>
</figure>
</div>
</div></div>
</section>
<section id="what-prosopagnosia-reveals" class="slide level2 center">
<h2>What prosopagnosia reveals</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Prosopagnosia demonstrates that:</p>
<ul>
<li>Face recognition is neurally specialized<br>
</li>
<li>Vision and recognition can dissociate<br>
</li>
<li>The higher order cortical areas can act as <code>expert systems</code></li>
</ul>
<p>Seeing is not the same as knowing.</p>
</div>
<div class="info-box">
<p>An expert system is a neural network that:</p>
<ul>
<li>Is highly <code>selective</code><br>
</li>
<li>Encodes complex, meaningful <code>patterns</code><br>
</li>
<li>Responds <code>efficiently</code> to familiar categories</li>
</ul>
</div>
</div><div class="column">
<div class="info-box">
<p>We discriminate faces:</p>
<ul>
<li>Rapidly (100-400 ms)</li>
<li>Automatically<br>
</li>
<li>With high precision</li>
</ul>
</div>
<div class="info-box">
<p>The <span class="highlight">grandmother neuron</span> hypothesis proposes that:</p>
<ul>
<li>A single neuron represents a specific, complex concept<br>
</li>
<li>For example, one neuron for your grandmother</li>
</ul>
</div>
</div></div>
</section>
<section id="problems-with-grandmother-neurons" class="slide level2 center">
<h2>Problems with grandmother neurons</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>A strict grandmother neuron model would be:</p>
<ul>
<li>Fragile to cell loss<br>
</li>
<li>Inflexible<br>
</li>
<li>Inefficient for representing many identities</li>
</ul>
<p>Most neuroscientists reject this literal interpretation.</p>
</div>
<div class="card">
<p>These neurons do not encode a single image. They respond to an <strong>abstract identity</strong>. They are better understood as:</p>
<ul>
<li>Highly selective nodes<br>
</li>
<li>Within a distributed representation</li>
</ul>
<p>Not isolated concept holders.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Higher-order cortex likely uses <strong>sparse coding</strong>.</p>
<p>This means:</p>
<ul>
<li>Few neurons respond strongly<br>
</li>
<li>Many neurons contribute weakly<br>
</li>
<li>Representations are distributed but efficient</li>
</ul>
<p>This balances specificity and robustness.</p>
</div>
</div></div>
</section>
<section id="spatial-localization-deficits" class="slide level2 center">
<h2>Spatial localization deficits</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Damage to dorsal areas impairs:</p>
<ul>
<li>Impaired perception of movement<br>
</li>
<li>Difficulty tracking moving objects</li>
</ul>
<p>In extreme cases, motion appears fragmented or absent.</p>
</div>
<div class="info-box">
<p><span class="highlight">Akinetopsia</span>, or motion blindness, is a rare condition linked to dorsal stream damage.</p>
<p>Patients perceive the world as a sequence of static snapshots.</p>
<p>Motion information fails to integrate over time.</p>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_akinetopsia.jpg" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="the-somatosensory-system" class="slide level2 center">
<h2>The somatosensory system</h2>
<p>The sense of touch allows the nervous system to detect mechanical stimulation of the body. Touch is not a single sense. It is a collection of specialized channels working together.</p>
<div class="columns">
<div class="column">
<div class="info-box">
<p>It provides information about:</p>
<ul>
<li>Contact<br>
</li>
<li>Pressure<br>
</li>
<li>Vibration<br>
</li>
<li>Stretch</li>
</ul>
<p>Touch is essential for interaction with the environment.</p>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-right">
<figure>
<p><img data-src="images/sen_touch.jpg" class="quarto-figure quarto-figure-right" width="100"></p>
</figure>
</div>
<div class="info-box">
<p>The somatosensory system includes multiple modalities:</p>
<ul>
<li>Light touch<br>
</li>
<li>Pressure and vibration<br>
</li>
<li>Skin stretch<br>
</li>
<li>Proprioception<br>
</li>
<li>Pain and temperature</li>
</ul>
<p>These modalities are detected by different receptor types.</p>
</div>
</div></div>
</section>
<section id="mechanoreceptors" class="slide level2 center">
<h2>Mechanoreceptors</h2>
<blockquote>
<p>Touch begins at <span class="highlight">mechanoreceptors</span>. These receptors convert mechanical forces into neural signals. Each type is tuned to specific stimulus properties.</p>
</blockquote>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Key mechanoreceptors in the skin include:</p>
<ul>
<li><p><strong>Meissner corpuscles</strong><br>
Sensitive to motion and light touch</p></li>
<li><p><strong>Merkel cells</strong><br>
Detect edges and fine detail</p></li>
<li><p><strong>Pacinian corpuscles</strong><br>
Detect vibration</p></li>
<li><p><strong>Ruffini endings</strong><br>
Detect skin stretch<br>
</p></li>
</ul>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_touch_term.png" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="spatial-acuity" class="slide level2 center">
<h2>Spatial acuity</h2>
<div class="columns">
<div class="column">
<div class="card">
<p>Each mechanoreceptor has a <strong>receptive field</strong>. This is the region of skin where stimulation affects that receptor. Smaller receptive fields allow finer spatial resolution.</p>
</div>
<div class="info-box">
<p>Touch sensitivity is <code>not uniform</code> across the body.</p>
<p>Regions such as:</p>
<ul>
<li>Fingertips<br>
</li>
<li>Lips</li>
</ul>
<p>Have higher receptor density and smaller receptive fields.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Touch intensity is encoded by:</p>
<ul>
<li>Firing rate<br>
</li>
<li>Number of activated receptors</li>
</ul>
</div>
<div class="info-box">
<p>Somatosensory information travels from:</p>
<ul>
<li>Peripheral receptors<br>
</li>
<li>Through spinal nerves<br>
</li>
<li>Into the central nervous system</li>
</ul>
<p>This information is organized and preserved along the pathway.</p>
</div>
</div></div>
</section>
<section id="two-major-somatosensory-pathways" class="slide level2 center">
<h2>Two major somatosensory pathways</h2>
<div class="columns">
<div class="column">
<p>Somatosensory information reaches the brain through <code>two main pathways</code>.</p>
<p>They differ in:</p>
<ul>
<li>The type of information they carry<br>
</li>
<li>Their anatomical routes<br>
</li>
<li>Their functional roles</li>
</ul>
<div class="info-box">
<p>The <strong>dorsal column pathway</strong> carries:</p>
<ul>
<li>Fine touch<br>
</li>
<li>Vibration<br>
</li>
<li>Proprioception</li>
</ul>
<p>This pathway supports precise spatial and discriminative touch.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>In the dorsal column pathway:</p>
<ul>
<li>Primary afferents enter the spinal cord<br>
</li>
<li>Ascend ipsilaterally in the dorsal columns<br>
</li>
<li><code>Synapse in the medulla</code><br>
</li>
<li><code>Cross</code> to the contralateral side<br>
</li>
<li>Project to the thalamus<br>
</li>
</ul>
</div>
</div></div>
</section>
<section id="spinothalamic-pathway" class="slide level2 center">
<h2>Spinothalamic pathway</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>The <strong>spinothalamic pathway</strong> carries:</p>
<ul>
<li>Pain<br>
</li>
<li>Temperature</li>
</ul>
<p>It is specialized for detecting potentially harmful stimuli.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>In the spinothalamic pathway:</p>
<ul>
<li>Primary afferents enter the spinal cord<br>
</li>
<li><code>Synapse almost immediately</code><br>
</li>
<li>Cross to the contralateral side near entry<br>
</li>
<li>Ascend to the thalamus<br>
</li>
</ul>
</div>
<div class="info-box">
<p>The two pathways differ in function:</p>
<ul>
<li><p><strong>Dorsal column</strong><br>
Precise, fast, spatially accurate</p></li>
<li><p><strong>Spinothalamic</strong><br>
Coarser, slower, protective</p></li>
</ul>
</div>
</div></div>
</section>
<section id="somatosensory-pathways" class="slide level2 center">
<h2>Somatosensory Pathways</h2>

<img data-src="images/sen_touch_pathways.png" class="quarto-figure quarto-figure-center r-stretch" width="700"></section>
<section id="S1" class="slide level2 center">
<h2>Primary somatosensory cortex</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Somatosensory information reaches <strong>primary somatosensory cortex</strong> (S1). S1 is located in the postcentral gyrus. It contains an ordered map of the body (Somatotopy).</p>
</blockquote>
<div class="info-box">
<p><code>Somatotopy</code> means that:</p>
<ul>
<li>Body position is mapped systematically<br>
</li>
<li>Neighboring body regions map to neighboring neural regions<br>
</li>
</ul>
</div>
</div><div class="column">
<blockquote>
<p>The <strong>sensory homunculus</strong> is a distorted body map. Body parts with high sensory acuity occupy more cortical space. Hands, lips, and face are overrepresented.</p>
</blockquote>
<p><img data-src="images/sen_touch_cortex.jpe" class="quarto-figure quarto-figure-left" width="300"> <iframe width="200" height="200" src="https://sketchfab.com/models/064a80c62d0942d8a5c89b43f5535182/embed" title="Homunculus"></iframe></p>
</div></div>
</section>
<section id="cortical-magnification-and-lesions" class="slide level2 center">
<h2>Cortical magnification and Lesions</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Cortical representation does not reflect body size.</p>
<p>It reflects:</p>
<ul>
<li>Receptor density<br>
</li>
<li>Behavioral relevance</li>
</ul>
<p>This parallels foveal magnification in vision.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Lesions in somatosensory cortex produce:</p>
<ul>
<li>Loss of sensation in specific body regions<br>
</li>
<li>Deficits that reflect the cortical map</li>
</ul>
<p>The pattern of loss reveals underlying organization.</p>
</div>
</div></div>
</section>
<section id="pain-as-a-distinct-system" class="slide level2 center">
<h2>Pain as a distinct system</h2>
<blockquote>
<p>Pain is not simply strong touch. It is a distinct sensory system specialized for detecting potential or actual tissue damage. Its primary function is protection, not perception.</p>
</blockquote>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Pain begins at specialized receptors called <span class="highlight">nociceptors</span>.</p>
<p>These receptors respond to:</p>
<ul>
<li>Mechanical damage<br>
</li>
<li>Extreme temperatures<br>
</li>
<li>Chemical irritants</li>
</ul>
<p>They are activated only when stimuli exceed safe limits and activate the Spinothalamic pathway.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Nociception is detected by <a href="#/mechanoreceptors">Free Nerve Endings</a> and there are two main fiber types:</p>
<ul>
<li><p><strong>Aδ fibers</strong><br>
Fast, sharp, well-localized pain</p></li>
<li><p><strong>C fibers</strong><br>
Slow, dull, poorly localized pain</p></li>
</ul>
<p>These produce different pain sensations.</p>
</div>
</div></div>
</section>
<section id="central-processing-of-pain" class="slide level2 center">
<h2>Central processing of pain</h2>
<div class="columns">
<div class="column">
<p>Pain processing involves multiple brain regions.</p>
<p>These include:</p>
<ul>
<li>Thalamus<br>
</li>
<li>Amygdala</li>
<li>Hyppocampus</li>
<li>Somatosensory cortex<br>
</li>
<li>Insular cortex<br>
</li>
<li>Anterior cingulate cortex<br>
</li>
<li>Prefrontal Cortex</li>
</ul>
<p>Pain has both sensory and emotional components.</p>
</div><div class="column">
<div class="quarto-figure quarto-figure-left">
<figure>
<p><img data-src="images/sen_touch_pain.jpg" class="quarto-figure quarto-figure-left" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="pain-is-multidimensional" class="slide level2 center">
<h2>Pain is multidimensional</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Pain includes:</p>
<ul>
<li><code>Sensory</code>-discriminative aspects<br>
</li>
<li><code>Affective</code>-motivational aspects<br>
</li>
<li><code>Cognitive</code> modulation<br>
</li>
</ul>
</div>
<div class="card">
<p><span class="highlight">Phantom pain</span> Pain can occur without peripheral input. <strong>Phantom pain</strong> arises after limb loss. This shows that pain is generated centrally, not only in the periphery.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Pain signals are not fixed.</p>
<p>They are <code>modulated</code> by:</p>
<ul>
<li><code>Descending</code> cortical control<br>
</li>
<li>Brainstem circuits<br>
</li>
<li><code>Context and expectation</code></li>
</ul>
<p>Pain perception is <code>dynamic</code>.</p>
</div>
</div></div>
</section>
<section id="the-auditory-system" class="slide level2 center">
<h2>The auditory system</h2>
<blockquote>
<p>Hearing allows the nervous system to detect and interpret sound. Sound is a <code>pattern of pressure waves in air</code>from 20 Hz to 20 kHz. Perception arises from how these waves are transformed into neural signals.</p>
</blockquote>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_sound.png" class="quarto-figure quarto-figure-center" width="400"></p>
</figure>
</div>
<div class="info-box">
<p>Sound waves are characterized by:</p>
<ul>
<li><span class="highlight">Frequency</span> related to perceived <code>pitch</code><br>
</li>
<li><span class="highlight">Amplitude</span> related to perceived <code>loudness</code>.</li>
</ul>
</div>
</div><div class="column">
<iframe src="tonegen.html" width="320" height="420" style="
    border: none;
    border-radius: 16px;
    background: #f4f4f4;
    box-shadow: 0 8px 24px rgba(0,0,0,0.35);
    overflow: hidden;
  ">
</iframe>
</div></div>
</section>
<section id="anatomy-of-the-ear" class="slide level2 center">
<h2>Anatomy of the ear</h2>
<div class="columns">
<div class="column">
<div class="info-box">
<p>The auditory system converts:</p>
<ul>
<li>Air pressure changes<br>
</li>
<li>Into mechanical vibrations<br>
</li>
<li>Into electrical signals</li>
</ul>
<p>This transformation occurs in specialized structures of the ear.</p>
</div>
<div class="info-box">
<p>The ear is divided into 3 main parts:</p>
<ul>
<li>Outer ear<br>
</li>
<li>Middle ear<br>
</li>
<li>Inner ear</li>
</ul>
<p>Each part performs a specific transformation.</p>
</div>
</div><div class="column">
<div class="card">
<p>The <code>outer ear</code> collects sound waves. The <code>middle ear</code> amplifies vibrations using <code>3 small bones</code>. This amplification is essential for efficient sound transmission.</p>
</div>
<div class="info-box">
<p>The inner ear contains the <span class="highlight">cochlea</span>.</p>
<p>Inside the cochlea:</p>
<ul>
<li>Sound vibrations create traveling waves<br>
</li>
<li>Different frequencies peak at different locations</li>
</ul>
<p>This spatial separation is fundamental to hearing.</p>
</div>
</div></div>
</section>
<section id="anatomy-of-the-ear-1" class="slide level2 center">
<h2>Anatomy of the ear</h2>
<p><img data-src="images/sen_sound_ear.png" class="quarto-figure quarto-figure-left" width="600" alt="Outer, Middle and Inner Ear"> <img data-src="images/sen_sound_cochlea.jpg" class="quarto-figure quarto-figure-right" width="400" alt="Cochlea"></p>
</section>
<section id="hair-cells" class="slide level2 center">
<h2>Hair cells</h2>
<div class="columns">
<div class="column">
<blockquote>
<p>Sensory transduction occurs in the Coorti organ, where <code>Hair Cells</code> convert mechanical movement into electrical signals. They are true <code>sensory receptors</code>.</p>
</blockquote>
<div class="info-box">
<p>Movement of hair bundles opens mechanically gated ion channels.</p>
<p>This leads to:</p>
<ul>
<li>Receptor potentials<br>
</li>
<li>Neurotransmitter release<br>
</li>
<li>Activation of auditory nerve fibers</li>
</ul>
<p>Sound is now encoded neurally.</p>
</div>
</div><div class="column">
<p><img data-src="images/sen_sound_coorti.gif" class="quarto-figure quarto-figure-right" width="400"> <img data-src="images/sen_sound_hair_cells.gif" class="quarto-figure quarto-figure-right" width="200"></p>
</div></div>
</section>
<section id="from-ear-to-brain" class="slide level2 center">
<h2>From ear to brain</h2>
<div class="info-box">
<p>Brainstem</p>
<blockquote>
<p>The first synapse occurs in the <span class="highlight">cochlear nuclei</span> of the brainstem. Information is split into parallel pathways. Different aspects of sound are processed simultaneously.</p>
</blockquote>
<blockquote>
<p>The <span class="highlight">superior olivary complex</span> is a key site for sound localization. It integrates input from both ears. Different nuclei specialize in timing and intensity comparisons.</p>
</blockquote>
</div>
<div class="info-box">
<p>From the brainstem, signals ascend through:</p>
<ul>
<li>Inferior colliculus<br>
</li>
<li>Medial Geniculate Nucleus (Thalamus)</li>
</ul>
</div>
</section>
<section id="interaural-level-differences" class="slide level2 center">
<h2>Interaural level differences</h2>
<div class="columns">
<div class="column">
<blockquote>
<p><strong>Interaural level differences</strong> arise from sound shadowing by the head. They are most informative for high-frequency sounds. These differences are computed in brainstem circuits.</p>
</blockquote>
<div class="info-box">
<p>The auditory system uses two main <code>interaural cues</code>:</p>
<ul>
<li>Interaural <code>time</code> differences (due to speed of sound)</li>
<li>Interaural <code>amplitude</code> differences (due to the acoustic shadow)</li>
</ul>
<p>Each cue is informative under different conditions.</p>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sen_sound_interaural.png" class="quarto-figure quarto-figure-center" width="500"></p>
</figure>
</div>
</div></div>
</section>
<section id="primary-auditory-cortex" class="slide level2 center">
<h2>Primary auditory cortex</h2>
<p>The <strong>primary auditory cortex</strong> is the first cortical stage of hearing. It is located in the temporal lobe. It receives organized input from the thalamus.</p>
<div class="columns">
<div class="column">
<blockquote>
<p>Primary auditory cortex is organized <code>tonotopically</code>: Neighboring neurons respond to neighboring sound frequencies.</p>
</blockquote>
<blockquote>
<p><code>Cortical magnification</code>: Frequencies important for communication occupy more cortical space. Representation reflects behavioral relevance, not physical frequency spacing.</p>
</blockquote>
</div><div class="column">
<div class="info-box">
<p>Damage to primary auditory cortex rarely causes deafness.</p>
<p>Instead, it impairs:</p>
<ul>
<li>Sound discrimination<br>
</li>
<li>Complex auditory perception</li>
</ul>
<p>Basic hearing often remains intact.</p>
</div>
</div></div>
</section>
<section id="beyond-primary-auditory-cortex" class="slide level2 center">
<h2>Beyond primary auditory cortex</h2>
<blockquote>
<p>Primary auditory cortex encodes basic acoustic features. However, hearing does not end in A1. Surrounding A1 are <span class="highlight">secondary auditory areas</span>. These regions receive input from A1 and from the thalamus. They integrate information over longer time windows.</p>
</blockquote>
<div class="columns">
<div class="column">
<div class="info-box">
<p>Higher-order areas respond to:</p>
<ul>
<li><code>Frequency</code> combinations<br>
</li>
<li><code>Temporal</code> patterns<br>
</li>
<li>Sound <code>sequences</code></li>
</ul>
<p>These features are essential for speech and music.</p>
</div>
</div><div class="column">
<div class="info-box">
<p>Higher-order auditory cortex supports <span class="highlight">auditory objects</span>. An auditory object is a coherent sound source over time. Like:</p>
<ul>
<li>A voice<br>
</li>
<li>A melody<br>
</li>
<li>A moving sound</li>
</ul>
<p>The brain groups sound features into <code>perceptual units</code>.</p>
</div>
</div></div>
</section>
<section id="self-check" class="slide level2 center">
<h2>Self-check</h2>
<div style="display: flex; justify-content: center;">
  <iframe src="quiz/quiz_5_sensory.html" style="
            width: 90vw;
            max-width: 900px;
            height: 80vh;
            border: none;
            border-radius: 16px;
          ">
  </iframe>
</div>



</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="images/logo/NEUROFARBA_logo.svg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    (function () {
      function injectHomeLink() {
        const link = document.createElement("a");
        link.href = "index.html";
        link.setAttribute("aria-label", "Back to Index");
        link.title = "Back to Index";

        // Positioning
        link.style.position = "absolute";
        link.style.bottom = "20px";
        link.style.left = "50%";
        link.style.transform = "translateX(-50%)";
        link.style.width = "28px";
        link.style.height = "28px";
        link.style.zIndex = "1000";
        link.style.display = "none";
        link.style.opacity = "0.75";
        link.style.cursor = "pointer";

        // Home icon image
        const img = document.createElement("img");
        img.src = "images/home.svg";
        img.alt = "Home";
        img.width = 28;
        img.height = 28;
        img.style.display = "block";

        link.appendChild(img);
        document.body.appendChild(link);

        // Hover feedback
        link.addEventListener("mouseenter", () => {
          link.style.opacity = "1";
          link.style.transform = "translateX(-50%) scale(2)";
        });

        link.addEventListener("mouseleave", () => {
          link.style.opacity = "0.75";
          link.style.transform = "translateX(-50%) scale(1)";
        });

        // Show only on title slide
        function updateVisibility() {
          if (document.body.classList.contains("title-slide")) {
            link.style.display = "block";
          } else {
            link.style.display = "none";
          }
        }

        updateVisibility();
        Reveal.on("slidechanged", updateVisibility);
        Reveal.on("ready", updateVisibility);
      }

      if (window.Reveal && Reveal.isReady()) {
        injectHomeLink();
      } else {
        document.addEventListener("DOMContentLoaded", function () {
          Reveal.on("ready", injectHomeLink);
        });
      }
    })();
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>